{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset into a Pandas DataFrame\n",
    "df_filtered = pd.read_csv(\"C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/labeled_records.csv\")\n",
    "df_icd = pd.read_csv(\"C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/MIMIC db/D_ICD_DIAGNOSES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SUBJECT_ID      39760\n",
       "HADM_ID         52074\n",
       "SEQ_NUM             4\n",
       "SHORT_CONCAT    78106\n",
       "LONG_CONCAT     78156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate 'short' column based on 'HADM' and 'SEQM'\n",
    "df_short = df_filtered.groupby(['SUBJECT_ID', 'HADM_ID', (df_filtered['SEQ_NUM']-1)//10])['SHORT_TITLE'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "df_short.rename(columns={'SHORT_TITLE': 'SHORT_CONCAT'}, inplace=True)\n",
    "\n",
    "# concatenate 'long' column based on 'HADM' and 'SEQM'\n",
    "df_long = df_filtered.groupby(['SUBJECT_ID', 'HADM_ID', (df_filtered['SEQ_NUM']-1)//10])['LONG_TITLE'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "df_long.rename(columns={'LONG_TITLE': 'LONG_CONCAT'}, inplace=True)\n",
    "\n",
    "\n",
    "# merge the two dataframes based on 'HADM' and SEQM_group\n",
    "df_concatenated = pd.merge(df_short, df_long, on=['SUBJECT_ID','HADM_ID', 'SEQ_NUM'])\n",
    "df_concatenated.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for ICD-9 code for keywords 'Heart failure'\n",
    "# Define the keywords to search for\n",
    "keywords = ['heart failure']\n",
    "\n",
    "# Create a new column with 1 if any of the keywords are found in the ICD9 code title, 0 otherwise\n",
    "df_concatenated['hf_all'] = df_concatenated['LONG_CONCAT'].apply(lambda x: 1 if any(keyword in x.lower() for keyword in keywords) else 0)\n",
    "\n",
    "#check for ICD-9 code for keywords 'Heart failure'\n",
    "# Define the keywords to search for\n",
    "keywords = ['without heart failure']\n",
    "\n",
    "# Create a new column with 1 if any of the keywords are found in the ICD9 code title, 0 otherwise\n",
    "df_concatenated['hf_no'] = df_concatenated['LONG_CONCAT'].apply(lambda x: 1 if any(keyword in x.lower() for keyword in keywords) else 0)\n",
    "\n",
    "df_concatenated['HF'] = df_concatenated['hf_all'] - df_concatenated['hf_no']\n",
    "\n",
    "#check for ICD-9 code for keywords 'Heart failure'\n",
    "# Define the keywords to search for\n",
    "keywords = ['Diabetes','diabetes']\n",
    "\n",
    "# Create a new column with 1 if any of the keywords are found in the ICD9 code title, 0 otherwise\n",
    "df_concatenated['Diabetes'] = df_concatenated['LONG_CONCAT'].apply(lambda x: 1 if any(keyword in x.lower() for keyword in keywords) else 0)\n",
    "\n",
    "df_concatenated = df_concatenated.drop(['hf_all','hf_no'], axis=1)\n",
    "\n",
    "df_concatenated.to_csv('C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/patient_wICD_concat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of splits\n",
    "num_splits = 5\n",
    "\n",
    "df_short = df_concatenated.drop(['LONG_CONCAT'], axis=1)\n",
    "\n",
    "# Calculate the split size\n",
    "split_size = int(np.ceil(len(df_short) / num_splits))\n",
    "\n",
    "# Split the dataframe\n",
    "df_split_short = [df_short[i:i+split_size] for i in range(0, len(df_short), split_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_split_short):\n",
    "    filename = f\"C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/patient_split_short_{i+1}.csv\" # create filename for each dataframe\n",
    "    df.to_csv(filename, index=False) # write dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_short_terms = df_icd.loc[df_icd['LONG_TITLE'].str.contains('heart failure'), 'SHORT_TITLE'].tolist()\n",
    "\n",
    "hf_short_terms_wcomma = [item + ',' for item in hf_short_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_split_short_mask = df_split_short_mask.reset_index(drop=True)\n",
    "# Define the masking probabilities\n",
    "delete_prob = 0.8\n",
    "unchanged_prob = 0.1\n",
    "replace_prob = 0.1\n",
    "\n",
    "def mask_short_concat(row):\n",
    "    # Check if any hf_term is present in the string\n",
    "    if any(term in row for term in hf_short_terms_wcomma):\n",
    "        # Apply the masking strategy\n",
    "        prob = random.uniform(0, 1)\n",
    "        if prob <= 0.8:\n",
    "            # Delete the hf_term from the string\n",
    "            for term in hf_short_terms_wcomma:\n",
    "                row = row.replace(term, '')\n",
    "        elif prob <= 0.9:\n",
    "            # Do nothing\n",
    "            pass\n",
    "        else:\n",
    "            # Replace the hf_term with 'Asthmatic'\n",
    "            for term in hf_short_terms_wcomma:\n",
    "                row = row.replace(term, 'Asthmatic, ')\n",
    "    return row\n",
    "\n",
    "# Loop through the first 4 dataframes in the list\n",
    "for i in range(4):\n",
    "    # Loop through the 'SHORT_CONCAT' column\n",
    "    df_split_short_mask[i]['SHORT_CONCAT'] = df_split_short_mask[i]['SHORT_CONCAT'].apply(mask_short_concat)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(df_split_short_mask):\n",
    "    filename = f\"C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/patient_split_shortmask_{i+1}.csv\" # create filename for each dataframe\n",
    "    df.to_csv(filename, index=False) # write dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short['SHORT_CONCAT'].to_csv('C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/patient_shortconcat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model files without any of the terms related to 'heart failure' and 'Diabetes' (diseases being trained for)\n",
    "all_short_terms = df_icd.loc[df_icd['LONG_TITLE'].str.contains('heart failure|diabetes|Diabetes'), 'SHORT_TITLE'].tolist()\n",
    "#all_short_terms_wcomma = [item + ',' for item in all_short_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vrl2k\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "df_split_short_removed = df_split_short\n",
    "def remove_short_concat(row):\n",
    "    # Check if any all_short_term is present in the string\n",
    "    for term in all_short_terms:\n",
    "        if term in row or term + ',' in row:\n",
    "            row = row.replace(term, '').replace(term + ',', '')\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Loop through the first 4 dataframes in the list\n",
    "for i in range(4):\n",
    "    # Loop through the 'SHORT_CONCAT' column\n",
    "    df_split_short_removed[i]['SHORT_CONCAT'] = df_split_short_removed[i]['SHORT_CONCAT'].apply(remove_short_concat)\n",
    "    \n",
    "for i, df in enumerate(df_split_short_removed):\n",
    "    filename = f\"C:/Users/vrl2k/Desktop/MS/Spring 2023/Deep Learning/Project/Proj_mimic_out/patient_split_shortremoved_{i+1}.csv\" # create filename for each dataframe\n",
    "    df.to_csv(filename, index=False) # write dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
